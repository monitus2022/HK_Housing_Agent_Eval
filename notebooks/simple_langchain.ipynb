{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1486f900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks import OpenAICallbackHandler\n",
    "\n",
    "# SQL agent\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "import sqlalchemy\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2817fc4",
   "metadata": {},
   "source": [
    "### List of models to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90cea976",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"llama_free\": \"meta-llama/llama-3.3-8b-instruct:free\",\n",
    "    \"deepseek_free\": \"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "    \"gemma_free\": \"google/gemma-3n-e4b-it:free\",\n",
    "    \"gemini\": \"google/gemini-2.5-flash-lite\",\n",
    "    \"llama_lunaris\": \"sao10k/l3-lunaris-8b\",\n",
    "    \"mistral\": \"mistralai/ministral-8b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4e4ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model availability\n",
    "def test_model_availability(model: str) -> bool:\n",
    "    client = OpenAI(\n",
    "        base_url=getenv(\"OPENROUTER_API_URL\"),\n",
    "        api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    )\n",
    "    try:\n",
    "        client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"test\"}],\n",
    "            max_tokens=1\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "        if \"region\" in error_msg or \"country\" in error_msg or \"blocked\" in error_msg:\n",
    "            print(f\"Model {model} is region-blocked.\")\n",
    "            return False  # Region-blocked\n",
    "        else:\n",
    "            pprint(e)  # Print other errors for debugging\n",
    "            return False\n",
    "\n",
    "# models = {\n",
    "#     model_name: model_id for model_name, model_id in models.items()\n",
    "#     if test_model_availability(model_id)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cdf7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer function to measure execution time\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution time: {round(end_time - start_time, 2)} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02efb70",
   "metadata": {},
   "source": [
    "### Create simple LangChain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a91ee609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 4.14 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To find the answer to who the President of the USA is, we can follow a logical process that involves checking the most recent information available and verifying through reliable sources. Here\\'s a step-by-step approach:\\n\\n1. **Stay Updated with Current News**: The first step is to stay updated with the latest news. Check reputable news websites, such as CNN, BBC, or the official website of the White House, for the latest political news.\\n\\n2. **Check Official Websites**: Visit the official website of the White House (whitehouse.gov) or the official website of the U.S. Government (usa.gov) for the most current information on the President of the United States.\\n\\n3. **Use Search Engines**: Search engines like Google can be very helpful. Simply typing \"President of the USA\" or \"Who is the current President of the United States?\" can give you the latest information.\\n\\n4. **Verify through Multiple Sources**: To ensure the accuracy of the information, verify it through multiple sources. Different news outlets and government websites should provide the same information.\\n\\n5. **Consider Historical Context**: If you\\'re investigating for historical reasons, look into past presidents to understand the progression of leadership in the United States.\\n\\nFollowing these steps should give you the most up-to-date and accurate information'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create first langchain agent to prompt LLM\n",
    "template = \"\"\"\n",
    "Question: {question}\n",
    "Answer: Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=getenv(\"OPENROUTER_API_URL\"),\n",
    "    model_name=models[\"llama_free\"],\n",
    "    max_completion_tokens=256\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "@timer\n",
    "def langchain_prompt(question: str) -> str:\n",
    "    return llm_chain.invoke(question)\n",
    "langchain_prompt(\"What is the president of the USA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80a6dc",
   "metadata": {},
   "source": [
    "### Connect to DB to fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a066019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.01 seconds\n",
      "| name       | region_name   | subregion_name   | district_name             | sm_district_name          |   location_lat |   location_lon | first_op_date       |   sell_count |   rent_count |   yearly_tx_count |   yearly_total_tx_amount |   yearly_net_ft_price |   yearly_net_ft_price_chg |   recent_ft_price |   recent_net_ft_price |   recent_tx_count |   recent_net_ft_price_chg |   recent_pre_net_ft_price |   recent_ft_price_chg |   recent_pre_ft_price |   recent_total_tx_amount | developer_name   | parent_estate_name   |\n",
      "|:-----------|:--------------|:-----------------|:--------------------------|:--------------------------|---------------:|---------------:|:--------------------|-------------:|-------------:|------------------:|-------------------------:|----------------------:|--------------------------:|------------------:|----------------------:|------------------:|--------------------------:|--------------------------:|----------------------:|----------------------:|-------------------------:|:-----------------|:---------------------|\n",
      "| Lohas Park | Kowloon       | Tseung Kwan O    | Lohas Park                | Lohas Park                |        22.2944 |         114.27 | 2008-12-08 00:00:00 |         1224 |          323 |               604 |              4.61391e+09 |               11748.9 |                     -0.22 |                 0 |                 11589 |                46 |                     -1.5  |                     11766 |                     0 |                     0 |              3.64961e+08 |                  |                      |\n",
      "| The Wings  | Kowloon       | Tseung Kwan O    | Tseung Kwan O Town Centre | Tseung Kwan O Town Centre |        22.3076 |         114.26 | 2011-08-30 00:00:00 |          249 |           46 |               116 |              1.18183e+09 |               16509.8 |                     -0.06 |                 0 |                 16672 |                 6 |                      0.48 |                     16592 |                     0 |                     0 |              5.41e+07    | SUN HUNG KAI     |                      |\n"
     ]
    }
   ],
   "source": [
    "# Connect to local duckdb to fetch data\n",
    "\n",
    "conn = duckdb.connect(\n",
    "    database=\"../data/housing_crawler_read_only.duckdb\",\n",
    "    read_only=True\n",
    ")\n",
    "\n",
    "@timer\n",
    "def query_housing_data(query: str) -> pd.DataFrame:\n",
    "    df = conn.execute(query).df()\n",
    "    # Remove id fields to minimize data size\n",
    "    id_fields = [col for col in df.columns if \"id\" in col.lower()]\n",
    "    df = df.drop(columns=id_fields)\n",
    "    return df\n",
    "\n",
    "def df_to_markdown(df: pd.DataFrame) -> str:\n",
    "    return df.to_markdown(index=False)\n",
    "\n",
    "df = query_housing_data(\"SELECT * FROM estate_info LIMIT 2;\")\n",
    "df_markdown = df_to_markdown(df)\n",
    "print(df_markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d640d6",
   "metadata": {},
   "source": [
    "### Use Markdown template for SQL generation using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aae7f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT name FROM estate_info WHERE region_name = 'Kowloon' ORDER BY yearly_tx_count DESC LIMIT 1;\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "# Use markdown table in prompt\n",
    "\n",
    "template_with_data = \"\"\"\n",
    "Here is an extract of the table called estate_info from Hong Kong Housing data from DuckDB:\n",
    "{table_data}\n",
    "Question: {question}\n",
    "Create SQL query to answer the question based on the data above.\n",
    "The SQL query will be executed on the same data.\n",
    "The respond should only contains the SQL query in plain text, not in code block.\n",
    "Do not include explanations or additional text.\n",
    "\"\"\"\n",
    "\n",
    "prompt_with_data = PromptTemplate(\n",
    "    template=template_with_data,\n",
    "    input_variables=[\"table_data\", \"question\"]\n",
    ")\n",
    "llm_chain_with_data = prompt_with_data | llm | StrOutputParser()\n",
    "\n",
    "token_count = OpenAICallbackHandler()\n",
    "response = llm_chain_with_data.with_config(callbacks=[token_count]).invoke(input={\n",
    "    \"table_data\": df_markdown, \n",
    "    \"question\": \"Which estate has the highest transaction volume in Kowloon?\"\n",
    "    })\n",
    "print(response)\n",
    "print(token_count.total_tokens)  # Check token usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a6165",
   "metadata": {},
   "source": [
    "### Create SQL agent directly instead of prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd144fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tc/Documents/Github/HK_Housing_Agent_Eval/env/lib/python3.12/site-packages/duckdb_engine/__init__.py:184: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
      "Action Input: \u001b[0m\u001b[38;5;200m\u001b[1;3mestate_info\u001b[0m\u001b[32;1m\u001b[1;3mNow that I know there's a table named 'estate_info', it relates to the question. I think I should get the schema to see what information it contains to construct a suitable query.\n",
      "\n",
      "Action: sql_db_schema\n",
      "Action Input: estate_info\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE estate_info (\n",
      "\tid VARCHAR, \n",
      "\tname VARCHAR, \n",
      "\tregion_id VARCHAR, \n",
      "\tregion_name VARCHAR, \n",
      "\tsubregion_id VARCHAR, \n",
      "\tsubregion_name VARCHAR, \n",
      "\tdistrict_id VARCHAR, \n",
      "\tdistrict_name VARCHAR, \n",
      "\tsm_district_id VARCHAR, \n",
      "\tsm_district_name VARCHAR, \n",
      "\tlocation_lat FLOAT, \n",
      "\tlocation_lon FLOAT, \n",
      "\tfirst_op_date DATE, \n",
      "\tsell_count INTEGER, \n",
      "\trent_count INTEGER, \n",
      "\tyearly_tx_count INTEGER, \n",
      "\tyearly_total_tx_amount FLOAT, \n",
      "\tyearly_net_ft_price FLOAT, \n",
      "\tyearly_net_ft_price_chg FLOAT, \n",
      "\trecent_ft_price FLOAT, \n",
      "\trecent_net_ft_price FLOAT, \n",
      "\trecent_tx_count INTEGER, \n",
      "\trecent_net_ft_price_chg FLOAT, \n",
      "\trecent_pre_net_ft_price FLOAT, \n",
      "\trecent_ft_price_chg FLOAT, \n",
      "\trecent_pre_ft_price FLOAT, \n",
      "\trecent_total_tx_amount FLOAT, \n",
      "\tdeveloper_name VARCHAR, \n",
      "\tparent_estate_id VARCHAR, \n",
      "\tparent_estate_name VARCHAR\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from estate_info table:\n",
      "id\tname\tregion_id\tregion_name\tsubregion_id\tsubregion_name\tdistrict_id\tdistrict_name\tsm_district_id\tsm_district_name\tlocation_lat\tlocation_lon\tfirst_op_date\tsell_count\trent_count\tyearly_tx_count\tyearly_total_tx_amount\tyearly_net_ft_price\tyearly_net_ft_price_chg\trecent_ft_price\trecent_net_ft_price\trecent_tx_count\trecent_net_ft_price_chg\trecent_pre_net_ft_price\trecent_ft_price_chg\trecent_pre_ft_price\trecent_total_tx_amount\tdeveloper_name\tparent_estate_id\tparent_estate_name\n",
      "E000004419\tLohas Park\t20\tKowloon\t2010\tTseung Kwan O\t201005\tLohas Park\t20100002\tLohas Park\t22.29439926147461\t114.26956176757812\t2008-12-08\t1224\t323\t604\t4613907456.0\t11748.8798828125\t-0.2199999988079071\t0.0\t11589.0\t46\t-1.5\t11766.0\t0.0\t0.0\t364960992.0\tNone\tNone\tNone\n",
      "E000010411\tThe Wings\t20\tKowloon\t2010\tTseung Kwan O\t201006\tTseung Kwan O Town Centre\t20100004\tTseung Kwan O Town Centre\t22.30763053894043\t114.26020050048828\t2011-08-30\t249\t46\t116\t1181832960.0\t16509.7890625\t-0.05999999865889549\t0.0\t16672.0\t6\t0.47999998927116394\t16592.0\t0.0\t0.0\t54100000.0\tSUN HUNG KAI\tNone\tNone\n",
      "P000000712\tLohas Park LP6\t20\tKowloon\t2010\tTseung Kwan O\t201005\tLohas Park\t20100002\tLohas Park\t22.292631149291992\t114.26996612548828\t2020-05-26\t234\t67\t74\t504636992.0\t13163.0302734375\t-0.25\t0.0\t13527.0\t4\t9.729999542236328\t12327.0\t0.0\t0.0\t22035000.0\tNAN FUNG GROUP / MTR\tE000004419\tLohas Park\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mFrom the schema and provided table 'estate_info', I can see the relevant columns to answer this question are 'name', 'region_name', 'recent_tx_count'. I can query by 'region_name' equal to 'Kowloon' and order by 'recent_tx_count' in descending order to get the estate with the highest transaction volume.\n",
      "\n",
      "Action: sql_db_query\n",
      "Action Input: \n",
      "SELECT name, region_name, recent_tx_count \n",
      "FROM estate_info \n",
      "WHERE region_name = 'Kowloon' \n",
      "ORDER BY recent_tx_count DESC \n",
      "LIMIT 10;\u001b[0m\u001b[36;1m\u001b[1;3m[('Lohas Park', 'Kowloon', 46), ('Mei Foo Sun Chuen', 'Kowloon', 29), ('Whampoa Garden', 'Kowloon', 23), ('Laguna City', 'Kowloon', 21), ('Park Central', 'Kowloon', 13), ('Metro City', 'Kowloon', 12), ('Ocean Shores', 'Kowloon', 12), ('Richland Gardens', 'Kowloon', 12), ('Amoy Gardens', 'Kowloon', 12), ('Cullinan Sky', 'Kowloon', 12)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer:\n",
      "\n",
      "Final Answer: Lohas Park has the highest transaction volume in Kowloon, with 46 recent transactions as of the provided data.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Execution time: 7.29 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lohas Park has the highest transaction volume in Kowloon, with 46 recent transactions as of the provided data.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=getenv(\"OPENROUTER_API_URL\"),\n",
    "    model_name=models[\"llama_lunaris\"],\n",
    "    max_completion_tokens=256\n",
    ")\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    \"duckdb:///../data/housing_crawler_read_only.duckdb\"\n",
    ")\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,  # Add verbose for debugging\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "@timer\n",
    "def langchain_sql_agent(question: str) -> str:\n",
    "    return agent.run(question)\n",
    "\n",
    "langchain_sql_agent(\"Which estate has the highest transaction volume in Kowloon?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
