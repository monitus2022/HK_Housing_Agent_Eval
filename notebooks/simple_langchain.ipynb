{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks import OpenAICallbackHandler\n",
    "\n",
    "# SQL agent\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317561b4",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- https://python.langchain.com/docs/tutorials/sql_qa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2817fc4",
   "metadata": {},
   "source": [
    "### List of models to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cea976",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"llama_free\": \"meta-llama/llama-3.3-8b-instruct:free\",\n",
    "    \"deepseek_free\": \"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "    \"gemma_free\": \"google/gemma-3n-e4b-it:free\",\n",
    "    \"gemini\": \"google/gemini-2.5-flash-lite\",\n",
    "    \"llama_lunaris\": \"sao10k/l3-lunaris-8b\",\n",
    "    \"mistral\": \"mistralai/ministral-8b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model availability\n",
    "def test_model_availability(model: str) -> bool:\n",
    "    client = OpenAI(\n",
    "        base_url=getenv(\"OPENROUTER_API_URL\"),\n",
    "        api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    )\n",
    "    try:\n",
    "        client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"test\"}],\n",
    "            max_tokens=1\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "        if \"region\" in error_msg or \"country\" in error_msg or \"blocked\" in error_msg:\n",
    "            print(f\"Model {model} is region-blocked.\")\n",
    "            return False  # Region-blocked\n",
    "        else:\n",
    "            pprint(e)  # Print other errors for debugging\n",
    "            return False\n",
    "\n",
    "# models = {\n",
    "#     model_name: model_id for model_name, model_id in models.items()\n",
    "#     if test_model_availability(model_id)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer function to measure execution time\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution time: {round(end_time - start_time, 2)} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02efb70",
   "metadata": {},
   "source": [
    "### Create simple LangChain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ee609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first langchain agent to prompt LLM\n",
    "template = \"\"\"\n",
    "Question: {question}\n",
    "Answer: Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=getenv(\"OPENROUTER_API_URL\"),\n",
    "    model_name=models[\"llama_free\"],\n",
    "    max_completion_tokens=256\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "@timer\n",
    "def langchain_prompt(question: str) -> str:\n",
    "    return llm_chain.invoke(question)\n",
    "langchain_prompt(\"What is the president of the USA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80a6dc",
   "metadata": {},
   "source": [
    "### Connect to DB to fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a066019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local duckdb to fetch data\n",
    "\n",
    "conn = duckdb.connect(\n",
    "    database=\"../data/housing_crawler_read_only.duckdb\",\n",
    "    read_only=True\n",
    ")\n",
    "\n",
    "@timer\n",
    "def query_housing_data(query: str) -> pd.DataFrame:\n",
    "    df = conn.execute(query).df()\n",
    "    # Remove id fields to minimize data size\n",
    "    id_fields = [col for col in df.columns if \"id\" in col.lower()]\n",
    "    df = df.drop(columns=id_fields)\n",
    "    return df\n",
    "\n",
    "def df_to_markdown(df: pd.DataFrame) -> str:\n",
    "    return df.to_markdown(index=False)\n",
    "\n",
    "df = query_housing_data(\"SELECT * FROM estate_info LIMIT 2;\")\n",
    "df_markdown = df_to_markdown(df)\n",
    "print(df_markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d640d6",
   "metadata": {},
   "source": [
    "### Use Markdown template for SQL generation using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use markdown table in prompt\n",
    "\n",
    "template_with_data = \"\"\"\n",
    "Here is an extract of the table called estate_info from Hong Kong Housing data from DuckDB:\n",
    "{table_data}\n",
    "Question: {question}\n",
    "Create SQL query to answer the question based on the data above.\n",
    "The SQL query will be executed on the same data.\n",
    "The respond should only contains the SQL query in plain text, not in code block.\n",
    "Do not include explanations or additional text.\n",
    "\"\"\"\n",
    "\n",
    "prompt_with_data = PromptTemplate(\n",
    "    template=template_with_data,\n",
    "    input_variables=[\"table_data\", \"question\"]\n",
    ")\n",
    "llm_chain_with_data = prompt_with_data | llm | StrOutputParser()\n",
    "\n",
    "token_count = OpenAICallbackHandler()\n",
    "response = llm_chain_with_data.with_config(callbacks=[token_count]).invoke(input={\n",
    "    \"table_data\": df_markdown, \n",
    "    \"question\": \"Which estate has the highest transaction volume in Kowloon?\"\n",
    "    })\n",
    "print(response)\n",
    "# print(token_count.total_tokens)  # Check token usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a6165",
   "metadata": {},
   "source": [
    "### Create SQL agent directly instead of prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd144fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=getenv(\"OPENROUTER_API_URL\"),\n",
    "    model_name=models[\"llama_lunaris\"],\n",
    "    max_completion_tokens=256\n",
    ")\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    \"duckdb:///../data/housing_crawler_read_only.duckdb\"\n",
    ")\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,  # Add verbose for debugging\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "token_count = OpenAICallbackHandler()\n",
    "\n",
    "@timer\n",
    "def langchain_sql_agent(question: str) -> str:\n",
    "    # return response and the token usage\n",
    "    response = agent.run(question, callbacks=[token_count])\n",
    "    print(f\"Total tokens used: {token_count}\")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_sql_agent(\"Which is the northernmost estate in Hong Kong?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49140d02",
   "metadata": {},
   "source": [
    "### Strategy to reduce token usage and speed up response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=getenv(\"OPENROUTER_API_URL\"),\n",
    "    model_name=models[\"llama_lunaris\"],\n",
    "    max_completion_tokens=256\n",
    ")\n",
    "\n",
    "# Disable row sampling\n",
    "db = SQLDatabase.from_uri(\n",
    "    database_uri=\"duckdb:///../data/housing_crawler_read_only.duckdb\",\n",
    "    sample_rows_in_table_info=0\n",
    ")\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    # verbose=True,  # Add verbose for debugging\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "token_count = OpenAICallbackHandler()\n",
    "\n",
    "@timer\n",
    "def langchain_sql_agent(question: str) -> str:\n",
    "    # return response and the token usage\n",
    "    response = agent.run(\n",
    "        input=\"You are a helpful assistant that helps people find information about housing in Hong Kong. Here is the user question. \" + question,\n",
    "        callbacks=[token_count]\n",
    "        )\n",
    "    print(f\"Total tokens used: {token_count}\")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_sql_agent(\"List top 10 estates in Hong Kong by transaction volume.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da330b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
